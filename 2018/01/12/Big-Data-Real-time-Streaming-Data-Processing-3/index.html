<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<!--
***************  *      *     *
      8          *    *       *
      8          *  *         *
      8          **           *
      8          *  *         *
      8          *    *       *
      8          *      *     *
      8          *        *   ***********    -----Theme By Kieran(http://go.kieran.top)
-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<!--<![endif]-->

<head>
  <title>分布式发布订阅消息系统Kafka | Thpffcj的树洞</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Hexo">
    <meta name="author" content="John Doe">
    <meta name="description" content="" />
    <meta name="keywords" content="" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/favicon.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
    
    <link rel="stylesheet" href="/highlightjs/vs.css" type="text/css">
    

    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->

  
  
  

  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style>
</head>

<!--
<body class="post-template">
-->
<body id="index" class="lightnav animsition">

      <!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            <li>
                <a class="sb-toggle-submenu">Works<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                        <li><a href="/" target="_BLANK" class="animsition-link">AAA</a></li>
                    
                        <li><a href="/atom.xml" target="_BLANK" class="animsition-link">BBB</a></li>
                    
                </ul>
            </li>
            
            
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a href="http://go.kieran.top/" class="animsition-link">Kieran</a></li>
                    
                    <li><a href="http://domain.com/" class="animsition-link">Name</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            <li><a href="/about.html" class="animsition-link" title="about">About</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="/img/logo.png" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Thpffcj</a></li>
                            <li class="nolink"><span>Always </span>Creative.</li>
                            
                            <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            <li><a href="https://twitter.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a></li>
                            
                            
                            <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a></li>
                            
                            
                            <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a></li>
                            
                            
                            <li><a href="http://weibo.com/" title="Sina-Weibo" target="_blank"><i class="icon-sina-weibo"></i></a></li>
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->


      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2018-01-12T00:35:13.000Z" itemprop="datePublished">
          2018-01-12
      </time>
    
    
    | 
    <a href='/tags/大数据/'>大数据</a>
    
    
</span>
                <h1>分布式发布订阅消息系统Kafka</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<ul>
<li>下面是这段时间系统了解Spark Streaming的一些记录<ul>
<li><a href="http://www.thpffcj.com/2018/01/10/Big-Data-Real-time-Streaming-Data-Processing-1/" target="_blank" rel="external">初识实时流处理</a></li>
<li><a href="http://www.thpffcj.com/2018/01/11/Big-Data-Real-time-Streaming-Data-Processing-2/" target="_blank" rel="external">分布式日志收集框架Flume</a></li>
<li><a href="http://www.thpffcj.com/2018/01/12/Big-Data-Real-time-Streaming-Data-Processing-3/" target="_blank" rel="external">分布式发布订阅消息系统Kafka</a></li>
<li><a href="http://www.thpffcj.com/2018/01/13/Big-Data-Real-time-Streaming-Data-Processing-4/" target="_blank" rel="external">Spark Streaming入门</a></li>
<li><a href="http://www.thpffcj.com/2018/01/14/Big-Data-Real-time-Streaming-Data-Processing-5/" target="_blank" rel="external">Spark Streaming整合Flume</a></li>
<li><a href="http://www.thpffcj.com/2018/01/15/Big-Data-Real-time-Streaming-Data-Processing-6/" target="_blank" rel="external">Spark Streaming整合Kafka</a></li>
<li><a href="http://www.thpffcj.com/2018/01/16/Big-Data-Real-time-Streaming-Data-Processing-7/" target="_blank" rel="external">Spark Streaming整合Flume&amp;Kafka打造通用流处理基础</a></li>
<li><a href="http://www.thpffcj.com/2018/01/17/Big-Data-Real-time-Streaming-Data-Processing-8/" target="_blank" rel="external">Spark Streaming项目实战</a></li>
<li><a href="http://www.thpffcj.com/2018/01/18/Big-Data-Real-time-Streaming-Data-Processing-9/" target="_blank" rel="external">可视化实战</a></li>
</ul>
</li>
</ul>
<p>上一篇博客我们了解了分布式日志收集框架Flume，我们把日志收集起来并不能直接让Spark Streaming进行处理计算，因为实时数据量可能非常大，这时候我们可以使用Kafka来接收Flume收集到的日志，然后Spark Streaming从Kafka里取出数据计算。Kafka以可水平扩展和高吞吐率而被广泛使用。我们这篇博客就来简单了解Kafka的组件以及常用配置使用。</p>
<hr>
<h2 id="1-Kafka概述"><a href="#1-Kafka概述" class="headerlink" title="1. Kafka概述"></a>1. Kafka概述</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><ul>
<li>官网：<a href="http://kafka.apache.org/" target="_blank" rel="external">kafka A distributed streaming platform</a></li>
<li><strong>PUBLISH &amp; SUBSCRIBE</strong><ul>
<li>Read and write streams of data like a messaging system.</li>
</ul>
</li>
<li><strong>PROCESS</strong><ul>
<li>Write scalable stream processing applications that react to events in real-time.</li>
</ul>
</li>
<li><strong>STORE</strong><ul>
<li>Store streams of data safely in a distributed, replicated, fault-tolerant cluster.</li>
</ul>
</li>
<li>Kafka is used for building real-time data pipelines and streaming apps. It is horizontally scalable, fault-tolerant, wicked fast, and runs in production in thousands of companies.</li>
<li>和消息系统类似(消息中间件：生产者和消费者)</li>
</ul>
<ul>
<li><strong>We think of a streaming platform as having three key capabilities:</strong><ul>
<li>It lets you publish and subscribe to streams of records. In this respect it is similar to a message queue or enterprise messaging system.</li>
<li>It lets you store streams of records in a fault-tolerant way.</li>
<li>It lets you process streams of records as they occur.</li>
</ul>
</li>
</ul>
<h3 id="2-Kafka架构及核心概念"><a href="#2-Kafka架构及核心概念" class="headerlink" title="2. Kafka架构及核心概念"></a>2. Kafka架构及核心概念</h3><p><img src="http://oseihavwm.bkt.clouddn.com/Kafka%E6%9E%B6%E6%9E%84.png" alt=""></p>
<ul>
<li>producer：生产者，生产馒头</li>
<li>consumer：消费者，吃馒头</li>
<li>broker：篮子</li>
<li>topic：主题，给馒头带一个标签，topica的馒头是给你吃的，topicb的馒头是给你弟弟吃的</li>
</ul>
<p><br></p>
<hr>
<h2 id="2-Kafka部署及使用"><a href="#2-Kafka部署及使用" class="headerlink" title="2. Kafka部署及使用"></a>2. Kafka部署及使用</h2><h3 id="1-部署"><a href="#1-部署" class="headerlink" title="1. 部署"></a>1. 部署</h3><ul>
<li>下载解压zookeeper <a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="external">Index of /cdh5/cdh/5</a></li>
</ul>
<pre><code>[thpffcj@thpffcj software]$ ls
apache-maven-3.5.2-bin.tar.gz   scala-2.12.4.tgz
flume-ng-1.6.0-cdh5.7.0.tar.gz  zookeeper-3.4.5-cdh5.7.0.tar.gz
[thpffcj@thpffcj software]$ tar -zxvf zookeeper-3.4.5-cdh5.7.0.tar.gz -C ~/app/
</code></pre><ul>
<li>配置到环境变量中，都是常规操作了</li>
</ul>
<pre><code>[thpffcj@thpffcj zookeeper-3.4.5-cdh5.7.0]$ vi ~/.bash_profile 

export ZOOKEEPER_HOME=/home/thpffcj/app/zookeeper-3.4.5-cdh5.7.0
export PATH=$ZOOKEEPER_HOME/bin:$PATH

[thpffcj@thpffcj zookeeper-3.4.5-cdh5.7.0]$ source ~/.bash_profile
</code></pre><ul>
<li>拷贝一份配置文件并作修改</li>
</ul>
<pre><code>[thpffcj@thpffcj conf]$ cp zoo_sample.cfg zoo.cfg
[thpffcj@thpffcj conf]$ vi zoo.cfg 

dataDir=/home/thpffcj/app/tmp/zookeeper
</code></pre><ul>
<li>启动</li>
</ul>
<pre><code>[thpffcj@thpffcj bin]$ ./zkServer.sh start
JMX enabled by default
Using config: /home/thpffcj/app/zookeeper-3.4.5-cdh5.7.0/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[thpffcj@thpffcj bin]$ jps
4931 Jps
4911 QuorumPeerMain
</code></pre><h3 id="2-单节点单Broker部署及使用"><a href="#2-单节点单Broker部署及使用" class="headerlink" title="2. 单节点单Broker部署及使用"></a>2. 单节点单Broker部署及使用</h3><ul>
<li>zookeeper配置成功我们才能进行相应Kafka的部署</li>
<li><strong>下载解压Kafka</strong></li>
</ul>
<pre><code>[thpffcj@thpffcj software]$ ls
apache-maven-3.5.2-bin.tar.gz   scala-2.12.4.tgz
flume-ng-1.6.0-cdh5.7.0.tar.gz  zookeeper-3.4.5-cdh5.7.0.tar.gz
kafka_2.11-0.9.0.0.tgz
[thpffcj@thpffcj software]$ tar -zxvf kafka_2.11-0.9.0.0.tgz -C ~/app/
</code></pre><ul>
<li>配置环境变量</li>
</ul>
<pre><code>export KAFKA_HOME=/home/thpffcj/app/kafka_2.11-0.9.0.0
export PATH=$KAFKA_HOME/bin:$PATH
</code></pre><ul>
<li>看一下配置文件config/server.properties，修改其中一些配置</li>
</ul>
<pre><code># Hostname the broker will bind to. If not set, the server will bind to all interfaces
host.name=thpffcj

# A comma seperated list of directories under which to store log files
log.dirs=/home/thpffcj/app/tmp/kafka-logs

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=thpffcj:2181
</code></pre><ul>
<li><strong>启动Kafka的server</strong><ul>
<li><blockquote>
<p>bin/kafka-server-start.sh config/server.properties</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-server-start.sh $KAFKA_HOME/config/server.properties

...
[2018-01-11 12:49:59,871] INFO Kafka version : 0.9.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2018-01-11 12:49:59,871] INFO Kafka commitId : fc7243c2af4b2b4a (org.apache.kafka.common.utils.AppInfoParser)
[2018-01-11 12:49:59,872] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
</code></pre><ul>
<li>查看进程</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ jps -m
3719 QuorumPeerMain /home/thpffcj/app/zookeeper-3.4.5-cdh5.7.0/bin/../conf/zoo.cfg
3917 Jps -m
3791 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server.properties
</code></pre><ul>
<li><strong>创建一个topic</strong><ul>
<li><blockquote>
<p>bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic test</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-topics.sh --create --zookeeper thpffcj:2181 --replication-factor 1 --partitions 1 --topic hello_topic
WARNING: Due to limitations in metric names, topics with a period (&apos;.&apos;) or underscore (&apos;_&apos;) could collide. To avoid issues it is best to use either, but not both.
Created topic &quot;hello_topic&quot;.
</code></pre><ul>
<li>查看zookeeper挂有多少个topic</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-topics.sh --list --zookeeper thpffcj:2181
hello_topic
</code></pre><ul>
<li><strong>发送消息</strong></li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-console-producer.sh --broker-list thpffcj:9092 --topic hello_topic
</code></pre><ul>
<li>这个9092就是上面server.properties中默认的配置<ul>
<li>listeners=PLAINTEXT://:9092</li>
</ul>
</li>
</ul>
<ul>
<li><strong>生产完之后我们可以启动一个消费者消费</strong></li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-console-consumer.sh --zookeeper thpffcj:2181 --topic hello_topic --from-beginning
</code></pre><ul>
<li>这个时候我们往生产者里面发送几个消息</li>
</ul>
<pre><code>hello
world
</code></pre><ul>
<li>发现生产者收到了这两条消息，我们关闭消费者，重新启动消费者，发现还能收到前面生产者发送的消息</li>
<li>–from-beginning的使用：这个参数代表从头开始消费</li>
<li>总结：<ul>
<li>创建topic：zk</li>
<li>发送消息：broker</li>
<li>消费消息：zk</li>
</ul>
</li>
</ul>
<h3 id="3-单节点多Broker部署及使用"><a href="#3-单节点多Broker部署及使用" class="headerlink" title="3. 单节点多Broker部署及使用"></a>3. 单节点多Broker部署及使用</h3><ul>
<li>拷贝三份配置文件</li>
</ul>
<pre><code>[thpffcj@thpffcj config]$ cp server.properties server-1.properties 
[thpffcj@thpffcj config]$ cp server.properties server-2.properties 
[thpffcj@thpffcj config]$ cp server.properties server-3.properties 
</code></pre><ul>
<li>修改配置文件</li>
</ul>
<pre><code>broker.id=1
listeners=PLAINTEXT://:9093
log.dirs=/home/thpffcj/app/tmp/kafka-logs-1

broker.id=2
listeners=PLAINTEXT://:9094
log.dirs=/home/thpffcj/app/tmp/kafka-logs-2

broker.id=3
listeners=PLAINTEXT://:9095
log.dirs=/home/thpffcj/app/tmp/kafka-logs-3
</code></pre><ul>
<li>后台启动节点</li>
</ul>
<pre><code>[thpffcj@thpffcj config]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server-1.properties &amp;
[1] 5057
[1]+  完成                  kafka-server-start.sh -daemon $KAFKA_HOME/config/server-1.properties
[thpffcj@thpffcj config]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server-2.properties &amp;
[1] 5125
[1]+  完成                  kafka-server-start.sh -daemon $KAFKA_HOME/config/server-2.properties
[thpffcj@thpffcj config]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server-3.properties &amp;
[1] 5182
[1]+  完成                  kafka-server-start.sh -daemon $KAFKA_HOME/config/server-3.properties
</code></pre><ul>
<li>查看进程</li>
</ul>
<pre><code>[thpffcj@thpffcj config]$ jps -m
5188 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server-3.properties
3719 QuorumPeerMain /home/thpffcj/app/zookeeper-3.4.5-cdh5.7.0/bin/../conf/zoo.cfg
5063 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server-1.properties
5131 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server-2.properties
5243 Jps -m
</code></pre><ul>
<li>创建一个topic信息</li>
</ul>
<pre><code>[thpffcj@thpffcj config]$ kafka-topics.sh --create --zookeeper thpffcj:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
Created topic &quot;my-replicated-topic&quot;.
</code></pre><ul>
<li>查看所有topic</li>
</ul>
<pre><code>[thpffcj@thpffcj config]$ kafka-topics.sh --list --zookeeper thpffcj:2181
hello_topic
my-replicated-topic
</code></pre><ul>
<li>启动生产者</li>
</ul>
<pre><code>[thpffcj@thpffcj config]$ kafka-console-producer.sh --broker-list thpffcj:9093,thpffcj:9094,thpffcj:9095 --topic my-replicated-topic
</code></pre><ul>
<li>启动一个消费者</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-console-consumer.sh --zookeeper thpffcj:2181 --topic my-replicated-topic
</code></pre><ul>
<li>输出一些信息</li>
</ul>
<pre><code>hadoop
spark
kafka
</code></pre><ul>
<li>可以看到消费者可以消费数据</li>
</ul>
<h3 id="4-Kafka容错性测试"><a href="#4-Kafka容错性测试" class="headerlink" title="4. Kafka容错性测试"></a>4. Kafka容错性测试</h3><pre><code>[thpffcj@thpffcj ~]$ kafka-topics.sh --describe --zookeeper thpffcj:2181 --topic my-replicated-topic
Topic:my-replicated-topic    PartitionCount:1    ReplicationFactor:3    Configs:
    Topic: my-replicated-topic    Partition: 0    Leader: 3    Replicas: 3,1,2    Isr: 3,1,2
</code></pre><ul>
<li>我们看到3号broker是一个主节点，那我们现在干掉一个从节点</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ jps -m
5842 ConsoleConsumer --zookeeper thpffcj:2181 --topic my-replicated-topic
5970 Jps -m
5188 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server-3.properties
3719 QuorumPeerMain /home/thpffcj/app/zookeeper-3.4.5-cdh5.7.0/bin/../conf/zoo.cfg
5063 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server-1.properties
5131 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server-2.properties
5822 ConsoleProducer --broker-list thpffcj:9093,thpffcj:9094,thpffcj:9095 --topic my-replicated-topic
[thpffcj@thpffcj ~]$ kill -9 5063
</code></pre><ul>
<li>我们再看一下详细信息</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-topics.sh --describe --zookeeper thpffcj:2181 --topic my-replicated-topic
Topic:my-replicated-topic    PartitionCount:1    ReplicationFactor:3    Configs:
    Topic: my-replicated-topic    Partition: 0    Leader: 3    Replicas: 3,1,2    Isr: 3,2
</code></pre><ul>
<li>活着的节点只有3和2了，现在杀死主节点</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kill -9 5188
[thpffcj@thpffcj ~]$ kafka-topics.sh --describe --zookeeper thpffcj:2181 --topic my-replicated-topic
Topic:my-replicated-topic    PartitionCount:1    ReplicationFactor:3    Configs:
    Topic: my-replicated-topic    Partition: 0    Leader: 2    Replicas: 3,1,2    Isr: 2
</code></pre><ul>
<li><strong>从生产者发消息生产者还是能够收到消息，2号节点成为主节点，虽然两个节点挂了，只要有一个副本正常，不影响Kafka的正常使用</strong></li>
</ul>
<p><br></p>
<hr>
<h2 id="3-Kafka-API编程"><a href="#3-Kafka-API编程" class="headerlink" title="3. Kafka API编程"></a>3. Kafka API编程</h2><ul>
<li><h3 id="github项目地址"><a href="#github项目地址" class="headerlink" title="github项目地址"></a><a href="https://github.com/Thpffcj/BigData-Getting-Started" target="_blank" rel="external">github项目地址</a></h3></li>
</ul>
<h3 id="1-IDEA-Maven构建开发环境"><a href="#1-IDEA-Maven构建开发环境" class="headerlink" title="1. IDEA+Maven构建开发环境"></a>1. IDEA+Maven构建开发环境</h3><ul>
<li>前面我们所采用的都是官方提供的控制台命令使用Kafka，现在我们使用开发环境使用Kafka</li>
<li>直接使用maven使用scala模板建立项目</li>
<li>pom中添加依赖</li>
</ul>
<pre><code>&lt;properties&gt;
    &lt;scala.version&gt;2.11.8&lt;/scala.version&gt;
    &lt;kafka.version&gt;0.9.0.0&lt;/kafka.version&gt;
    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
&lt;/properties&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;kafka_2.11&lt;/artifactId&gt;
    &lt;version&gt;${kafka.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><h3 id="2-Producer-API的使用"><a href="#2-Producer-API的使用" class="headerlink" title="2. Producer API的使用"></a>2. Producer API的使用</h3><ul>
<li>新建一个类做默认配置</li>
</ul>
<pre><code>package cn.edu.nju.spark.kafka;

/**
 * Created by Thpffcj on 2018/1/11.
 * Kafka常用配置文件
 */
public class KafkaProperties {

    public static final String ZOOKEEPER = &quot;192.168.92.130:2181&quot;;
    public static final String TOPIC = &quot;hello_topic&quot;;
    public static final String BROKER_LIST = &quot;192.168.92.130:9092&quot;;

}
</code></pre><ul>
<li>编写生产者类</li>
</ul>
<pre><code>package cn.edu.nju.spark.kafka;

import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;
import kafka.producer.ProducerConfig;

import java.util.Properties;

/**
 * Created by Thpffcj on 2018/1/11.
 */
public class KafkaProducer extends Thread {

    private String topic;

    private Producer&lt;Integer, String&gt; producer;

    public KafkaProducer(String topic) {
        this.topic = topic;

        Properties properties = new Properties();
        properties.put(&quot;metadata.broker.list&quot;, KafkaProperties.BROKER_LIST);
        properties.put(&quot;serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;);
        properties.put(&quot;request.required.acks&quot;, &quot;1&quot;);

        producer = new Producer&lt;Integer, String&gt;(new ProducerConfig(properties));
    }

    @Override
    public void run() {

        int messageNo = 1;

        while (true) {
            String message = &quot;message_&quot; + messageNo;
            producer.send(new KeyedMessage&lt;Integer, String&gt;(topic, message));
            System.out.println(&quot;Sent：&quot; + message);

            messageNo++;

            try {
                Thread.sleep(2000);
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}
</code></pre><ul>
<li>写一个测试类调用run方法</li>
</ul>
<pre><code>package cn.edu.nju.spark.kafka;

/**
 * Created by Thpffcj on 2018/1/11.
 */
public class KafkaClientApp {

    public static void main(String[] args) {
        new KafkaProducer(KafkaProperties.TOPIC).start();
    }
}
</code></pre><ul>
<li>我们生产消息，需要有一个消费者去消费</li>
<li>在虚拟机启动一个消费者</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ jps
3719 QuorumPeerMain
7086 Jps
6991 Kafka
[thpffcj@thpffcj ~]$ kafka-console-consumer.sh --zookeeper thpffcj:2181 --topic hello_topic
</code></pre><ul>
<li>运行KafkaClientApp，发现什么都没有输出，想到前面学习redis和hadoop的时候都出现过这种情况，centos7默认是不开放端口的，开放端口</li>
</ul>
<pre><code>[root@thpffcj ~]# firewall-cmd --zone=public --add-port=9092/tcp --permanent
success
[root@thpffcj ~]# firewall-cmd --reload
success
</code></pre><ul>
<li>出现新的错误</li>
</ul>
<pre><code>Exception in thread &quot;Thread-0&quot; kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
    at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:91)
    at kafka.producer.Producer.send(Producer.scala:77)
    at kafka.javaapi.producer.Producer.send(Producer.scala:33)
    at cn.edu.nju.spark.kafka.KafkaProducer.run(KafkaProducer.java:36) 
</code></pre><ul>
<li>我换了一个topic kafka-topic还是没有用，网上指出要修改一个配置<ul>
<li>advertised.host.name=192.168.92.130</li>
</ul>
</li>
<li>我把上面那个配置打开以后可以正常运行</li>
</ul>
<pre><code>Sent：message_1
Sent：message_2
Sent：message_3
</code></pre><ul>
<li><strong>虚拟机消费者也能收到消息，后面有尝试不同的修改，比如把thpffcj和192.168.92.130互改，发现必须要写成advertised.host.name=192.168.92.130，其他配置可以使用以前的thpffcj，也可以换成192.168.92.130，不太懂为什么，不过目前可以连通</strong></li>
</ul>
<h3 id="3-Consumer-API的使用"><a href="#3-Consumer-API的使用" class="headerlink" title="3. Consumer API的使用"></a>3. Consumer API的使用</h3><ul>
<li>开发完生产者，我们来看一下如何使用代码开发消费者</li>
<li>配置类</li>
</ul>
<pre><code>package cn.edu.nju.spark.kafka;

/**
 * Created by Thpffcj on 2018/1/11.
 * Kafka常用配置文件
 */
public class KafkaProperties {

    public static final String ZOOKEEPER = &quot;192.168.92.130:2181&quot;;
    public static final String TOPIC = &quot;kafka-topic&quot;;
    public static final String BROKER_LIST = &quot;192.168.92.130:9092&quot;;
    public static final String GROUP_ID = &quot;test_group1&quot;;
}
</code></pre><ul>
<li>consumer类，其实与生产者类似</li>
</ul>
<pre><code>package cn.edu.nju.spark.kafka;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

/**
 * Created by Thpffcj on 2018/1/11.
 */
public class KafkaConsumer extends Thread {

    private String topic;

    public KafkaConsumer(String topic) {
        this.topic = topic;
    }

    private ConsumerConnector createConnector() {

        Properties properties = new Properties();
        properties.put(&quot;zookeeper.connect&quot;, KafkaProperties.ZOOKEEPER);
        properties.put(&quot;group.id&quot;, KafkaProperties.GROUP_ID);

        return Consumer.createJavaConsumerConnector(new ConsumerConfig(properties));
    }

    @Override
    public void run() {
        ConsumerConnector consumer = createConnector();

        Map&lt;String, Integer&gt; topicCountMap = new HashMap&lt;String, Integer&gt;();
        topicCountMap.put(topic, 1);

        // String: topic
        // List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;  对应的数据流
        Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; messageStream =  consumer.createMessageStreams(topicCountMap);

        KafkaStream&lt;byte[], byte[]&gt; stream = messageStream.get(topic).get(0);   //获取我们每次接收到的数据

        ConsumerIterator&lt;byte[], byte[]&gt; iterator = stream.iterator();

        while (iterator.hasNext()) {
            String message = new String(iterator.next().message());
            System.out.println(&quot;rec: &quot; + message);
        }
    }
}
</code></pre><ul>
<li>在main里添加运行</li>
</ul>
<pre><code>package cn.edu.nju.spark.kafka;

/**
 * Created by Thpffcj on 2018/1/11.
 */
public class KafkaClientApp {

    public static void main(String[] args) {
        new KafkaProducer(KafkaProperties.TOPIC).start();
        new KafkaConsumer(KafkaProperties.TOPIC).start();
    }
}
</code></pre><ul>
<li>执行，记得打开2181端口</li>
</ul>
<pre><code>log4j:WARN No appenders could be found for logger (kafka.utils.VerifiableProperties).
log4j:WARN Please initialize the log4j system properly.
Sent：message_1
Sent：message_2
rec: message_2
Sent：message_3
rec: message_3
rec: message_4
Sent：message_4
Sent：message_5
rec: message_5
...
</code></pre><p><br></p>
<hr>
<h2 id="4-Kafka实战"><a href="#4-Kafka实战" class="headerlink" title="4. Kafka实战"></a>4. Kafka实战</h2><ul>
<li><p>需求：整合Flume和Kafka完成实时数据采集</p>
</li>
<li><p>下图Agent1中的 avro source 应该为 exec source</p>
</li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/Flume+Kafka.png" alt=""></p>
<ul>
<li>我们看下Agent1配置，和上篇学习Flume博客一样不需要改变</li>
</ul>
<pre><code>[thpffcj@thpffcj conf]$ cat exec-memory-avro.conf 
# Name the components on this agent
exec-memory-avro.sources = exec-source
exec-memory-avro.sinks = avro-sink
exec-memory-avro.channels = memory-channel

# Describe/configure the source
exec-memory-avro.sources.exec-source.type = exec
exec-memory-avro.sources.exec-source.command = tail -F /home/thpffcj/data/data.log
exec-memory-avro.sources.exec-source.shell = /bin/sh -c

# Describe the sink
exec-memory-avro.sinks.avro-sink.type = avro
exec-memory-avro.sinks.avro-sink.hostname = thpffcj
exec-memory-avro.sinks.avro-sink.port = 44444

# Use a channel which buffers events in memory
exec-memory-avro.channels.memory-channel.type = memory

# Bind the source and sink to the channel
exec-memory-avro.sources.exec-source.channels = memory-channel
exec-memory-avro.sinks.avro-sink.channel = memory-channel
</code></pre><ul>
<li><strong>Agent2的配置我们需要把logger-sink换成kafka-sink(Flume 1.6版本，不同版本配置可以去官网查看，1.6与1.7配置略有不同)</strong></li>
</ul>
<pre><code># name the components on this agent
avro-memory-kafka.sources = avro-source
avro-memory-kafka.sinks = kafka-sink
avro-memory-kafka.channels = memory-channel

# Describe/configure the source
avro-memory-kafka.sources.avro-source.type = avro
avro-memory-kafka.sources.avro-source.bind = thpffcj
avro-memory-kafka.sources.avro-source.port = 44444

# Describe the sink
avro-memory-kafka.sinks.kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
avro-memory-kafka.sinks.kafka-sink.brokerList = thpffcj:9092
avro-memory-kafka.sinks.kafka-sink.topic = kafka-topic
avro-memory-kafka.sinks.kafka-sink.batchSize = 5
avro-memory-kafka.sinks.kafka-sink.requiredAcks = 1

# Use a channel which buffers events in memory
avro-memory-kafka.channels.memory-channel.type = memory

# Bind the source and sink to the channel
avro-memory-kafka.sources.avro-source.channels = memory-channel
avro-memory-kafka.sinks.kafka-sink.channel = memory-channel
</code></pre><ul>
<li>先启动Agent2</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ flume-ng agent \
&gt; --name avro-memory-kafka \
&gt; --conf $FLUME_HOME/conf \
&gt; --conf-file $FLUME_HOME/conf/avro-memory-kafka.conf \
&gt; -Dflume.root.logger=INFO,console
</code></pre><ul>
<li>先启动Agent1</li>
</ul>
<pre><code>flume-ng agent \
--name exec-memory-avro \
--conf $FLUME_HOME/conf \
--conf-file $FLUME_HOME/conf/exec-memory-avro.conf \
-Dflume.root.logger=INFO,console
</code></pre><ul>
<li>启动kafka</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ kafka-server-start.sh $KAFKA_HOME/config/server.properties
</code></pre><ul>
<li>查看进程，现在kafka在跑了，两个flume在跑</li>
</ul>
<pre><code>[thpffcj@thpffcj ~]$ jps -m
4152 QuorumPeerMain /home/thpffcj/app/zookeeper-3.4.5-cdh5.7.0/bin/../conf/zoo.cfg
7082 Kafka /home/thpffcj/app/kafka_2.11-0.9.0.0/config/server.properties
7162 Jps -m
6411 Application --name avro-memory-kafka --conf-file /home/thpffcj/app/apache-flume-1.6.0-cdh5.7.0-bin/conf/avro-memory-kafka.conf
6748 Application --name exec-memory-avro --conf-file /home/thpffcj/app/apache-flume-1.6.0-cdh5.7.0-bin/conf/exec-memory-avro.conf
</code></pre><ul>
<li>启动一个kafka的客户端来消费</li>
</ul>
<pre><code>[thpffcj@thpffcj conf]$ kafka-console-producer.sh --broker-list thpffcj:9092 --topic kafka-topic
</code></pre><ul>
<li>和上一篇博客一样，我们再向Agent1监控的文件中写一点数据进去</li>
</ul>
<pre><code>[thpffcj@thpffcj data]$ echo hellospark &gt;&gt; data.log 
[thpffcj@thpffcj data]$ echo hellospark2 &gt;&gt; data.log 
[thpffcj@thpffcj data]$ echo hellospark3 &gt;&gt; data.log 
[thpffcj@thpffcj data]$ echo hellospark4 &gt;&gt; data.log 
[thpffcj@thpffcj data]$ echo hellospark5 &gt;&gt; data.log 
</code></pre><ul>
<li>去kafka消费者看，发现成功收到消息</li>
</ul>
<pre><code>hellospark
hellospark2
hellospark3
hellospark4
hellospark5
</code></pre><ul>
<li>到现在为止，我们把实时添加的日志通过Flume收集到Kafak中</li>
</ul>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="pagination" role="pagination">
    
    <a class="pull-left" href="/2018/01/13/Big-Data-Real-time-Streaming-Data-Processing-4/" style="float: left;">
        ← Spark Streaming入门
    </a>
    
    
    <a class="pull-right" href="/2018/01/11/Big-Data-Real-time-Streaming-Data-Processing-2/">
        分布式日志收集框架Flume →
    </a>
    
</nav>

        <div class="duoshuo">


</div>
    </div>
</section>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
				<span id="busuanzi_container_site_pv">
					本站总访问量<span id="busuanzi_value_site_pv"></span>次
				</span>	
                <p>
                    &copy; 2014<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By Thpffcj.
                </p>
                <p>私は再び1日満たすためにあなたとの重要な人々を望みます</p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://twitter.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="http://weibo.com/" title="Sina-Weibo" target="_blank"><i class="icon-sina-weibo"></i></a>&nbsp;</li>
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- ============================ END Footer =========================== -->

      <!-- Load our scripts -->
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };

    resizeHero();

    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/jquery.flexslider-min.js"></script><!-- Flexslider plugin -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$('#intro').find('img').each(function(){
  var alt = this.alt;

  if (alt){
    $(this).after('<span class="caption" style="display:none">' + alt + '</span>');
  }

  $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="gallery" />');
});
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<!-- Initiate flexslider plugin -->
<script type="text/javascript">
    $(document).ready(function($) {
      (function(){
        console.log('font');
        var getCss = function(path) {
          var head = document.getElementsByTagName('head')[0];
          link = document.createElement('link');
          link.href = path;
          link.rel = 'stylesheet';
          link.type = 'text/css';
          head.appendChild(link);
        };
        getCss('https://fonts.googleapis.com/css?family=Montserrat:400,700');
        getCss('https://fonts.googleapis.com/css?family=Open+Sans:400,600');
      })();
      $('.flexslider').flexslider({
        animation: "fade",
        prevText: "",
        nextText: "",
        directionNav: true
      });
    });
</script>

</body>
</html>
