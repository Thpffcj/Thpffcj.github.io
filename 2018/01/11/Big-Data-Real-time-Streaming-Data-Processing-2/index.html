<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<!--
***************  *      *     *
      8          *    *       *
      8          *  *         *
      8          **           *
      8          *  *         *
      8          *    *       *
      8          *      *     *
      8          *        *   ***********    -----Theme By Kieran(http://go.kieran.top)
-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<!--<![endif]-->

<head>
  <title>分布式日志收集框架Flume | Thpffcj的树洞</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Hexo">
    <meta name="author" content="John Doe">
    <meta name="description" content="" />
    <meta name="keywords" content="" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/favicon.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
    
    <link rel="stylesheet" href="/highlightjs/vs.css" type="text/css">
    

    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->

  
  
  

  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style>
</head>

<!--
<body class="post-template">
-->
<body id="index" class="lightnav animsition">

      <!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            <li>
                <a class="sb-toggle-submenu">Works<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                        <li><a href="/" target="_BLANK" class="animsition-link">AAA</a></li>
                    
                        <li><a href="/atom.xml" target="_BLANK" class="animsition-link">BBB</a></li>
                    
                </ul>
            </li>
            
            
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a href="http://go.kieran.top/" class="animsition-link">Kieran</a></li>
                    
                    <li><a href="http://domain.com/" class="animsition-link">Name</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            <li><a href="/about.html" class="animsition-link" title="about">About</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="/img/logo.png" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Thpffcj</a></li>
                            <li class="nolink"><span>Always </span>Creative.</li>
                            
                            <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            <li><a href="https://twitter.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a></li>
                            
                            
                            <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a></li>
                            
                            
                            <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a></li>
                            
                            
                            <li><a href="http://weibo.com/" title="Sina-Weibo" target="_blank"><i class="icon-sina-weibo"></i></a></li>
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->


      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2018-01-11T07:57:13.000Z" itemprop="datePublished">
          2018-01-11
      </time>
    
    
    | 
    <a href='/tags/大数据/'>大数据</a>
    
    
</span>
                <h1>分布式日志收集框架Flume</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<ul>
<li>下面是这段时间系统了解Spark Streaming的一些记录<ul>
<li><a href="http://www.thpffcj.com/2018/01/10/Big-Data-Real-time-Streaming-Data-Processing-1/" target="_blank" rel="external">初识实时流处理</a></li>
<li><a href="http://www.thpffcj.com/2018/01/11/Big-Data-Real-time-Streaming-Data-Processing-2/" target="_blank" rel="external">分布式日志收集框架Flume</a></li>
<li><a href="http://www.thpffcj.com/2018/01/12/Big-Data-Real-time-Streaming-Data-Processing-3/" target="_blank" rel="external">分布式发布订阅消息系统Kafka</a></li>
<li><a href="http://www.thpffcj.com/2018/01/13/Big-Data-Real-time-Streaming-Data-Processing-4/" target="_blank" rel="external">Spark Streaming入门</a></li>
<li><a href="http://www.thpffcj.com/2018/01/14/Big-Data-Real-time-Streaming-Data-Processing-5/" target="_blank" rel="external">Spark Streaming整合Flume</a></li>
<li><a href="http://www.thpffcj.com/2018/01/15/Big-Data-Real-time-Streaming-Data-Processing-6/" target="_blank" rel="external">Spark Streaming整合Kafka</a></li>
<li><a href="http://www.thpffcj.com/2018/01/16/Big-Data-Real-time-Streaming-Data-Processing-7/" target="_blank" rel="external">Spark Streaming整合Flume&amp;Kafka打造通用流处理基础</a></li>
<li><a href="http://www.thpffcj.com/2018/01/17/Big-Data-Real-time-Streaming-Data-Processing-8/" target="_blank" rel="external">Spark Streaming项目实战</a></li>
<li><a href="http://www.thpffcj.com/2018/01/18/Big-Data-Real-time-Streaming-Data-Processing-9/" target="_blank" rel="external">可视化实战</a></li>
</ul>
</li>
</ul>
<p>在了解了实时流处理的基本流程，我们这篇博客主要就要来学习分布式日志收集框架Flume，了解一下为什么会出现Flume，Flume核心组件以及他的基本配置。</p>
<hr>
<h2 id="1-Flume概述"><a href="#1-Flume概述" class="headerlink" title="1. Flume概述"></a>1. Flume概述</h2><h3 id="1-业务现状分析"><a href="#1-业务现状分析" class="headerlink" title="1. 业务现状分析"></a>1. 业务现状分析</h3><ul>
<li>WebServer/ApplicationServer分散在各个机器上</li>
<li>想使用大数据平台Hadoop进行统计分析</li>
<li>日志如何收集到Hadoop平台上</li>
<li>解决方案<ul>
<li>shell cp hadoop集群的机器上，然后hadoop -fs put</li>
<li>Flume</li>
</ul>
</li>
</ul>
<h3 id="2-Flume概述"><a href="#2-Flume概述" class="headerlink" title="2. Flume概述"></a>2. Flume概述</h3><ul>
<li>Flume官网：<strong><a href="http://flume.apache.org/" target="_blank" rel="external">Apache Flume</a></strong></li>
<li>Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.<ul>
<li>webserver(源端) =&gt; flume =&gt; hdfs(目的地)</li>
</ul>
</li>
<li>It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms. It uses a simple extensible data model that allows for online analytic application.</li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/Flume%E6%9E%B6%E6%9E%84.png" alt=""></p>
<ul>
<li>Flume是由Apache提供的分布式，高可靠，高可用的服务，用于分布式的海量日志的高效收集，聚合，移动系统</li>
<li>设计目标<ul>
<li>可靠性</li>
<li>扩展性</li>
<li>管理性</li>
</ul>
</li>
<li>业界同类产品<ul>
<li>Flume</li>
<li>Scribe</li>
<li>Chukwa</li>
<li>Fluentd</li>
<li>Logstash：ELK(ElasticSearch, Logstash, Kibana)</li>
</ul>
</li>
</ul>
<h3 id="3-Flume架构及核心组件"><a href="#3-Flume架构及核心组件" class="headerlink" title="3. Flume架构及核心组件"></a>3. Flume架构及核心组件</h3><p>通过上面的图，我们可以看到Flume有三大组件:</p>
<ul>
<li>Source：收集</li>
<li>Channel：聚集</li>
<li>Sink：输出</li>
</ul>
<p>其他架构：</p>
<ul>
<li><strong>multi-agent flow</strong></li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/%E5%A4%9A%E7%94%A8%E6%88%B7%E6%B5%81.png" alt=""></p>
<ul>
<li><strong>Consolidation</strong></li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/Flume%20consolidation.png" alt=""></p>
<ul>
<li><strong>Multiplexing the flow</strong></li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/Flume%20multiplexing%20the%20flow.png" alt=""></p>
<p><br></p>
<hr>
<h2 id="2-Flume实战"><a href="#2-Flume实战" class="headerlink" title="2. Flume实战"></a>2. Flume实战</h2><h3 id="1-Flume环境部署"><a href="#1-Flume环境部署" class="headerlink" title="1. Flume环境部署"></a>1. Flume环境部署</h3><ul>
<li>前置条件：<ul>
<li>Java Runtime Environment - Java 1.8 or later</li>
<li>Memory - Sufficient memory for configurations used by sources, channels or sinks</li>
<li>Disk Space - Sufficient disk space for configurations used by channels or sinks</li>
<li>Directory Permissions - Read/Write permissions for directories used by agent</li>
</ul>
</li>
</ul>
<ul>
<li>安装jdk(学习Hadoop时安装过了)<ul>
<li>下载</li>
<li>解压到~/app</li>
<li>将java配置系统环境变量中</li>
<li>source使其生效</li>
</ul>
</li>
</ul>
<h3 id="2-Flume安装"><a href="#2-Flume安装" class="headerlink" title="2. Flume安装"></a>2. Flume安装</h3><ul>
<li>到 <a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="external">Index of /cdh5/cdh/5</a> 下载合适版本Flume</li>
</ul>
<pre><code>[thpffcj@localhost software]$ ls
apache-maven-3.5.2-bin.tar.gz            scala-2.12.4.tgz
flink-1.4.0-bin-hadoop26-scala_2.11.tgz  spark-2.1.0-bin-hadoop2.6.tgz
flume-ng-1.6.0-cdh5.7.0.tar.gz           word-count-beam
hadoop-2.6.0-cdh5.7.0.tar.gz
[thpffcj@localhost software]$ tar -zvxf flume-ng-1.6.0-cdh5.7.0.tar.gz -C ~/app/
</code></pre><ul>
<li>查看目录结构</li>
</ul>
<pre><code>[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ ll
总用量 136
drwxr-xr-x.  2 thpffcj thpffcj    62 3月  24 2016 bin
-rw-r--r--.  1 thpffcj thpffcj 69856 3月  24 2016 CHANGELOG
drwxr-xr-x.  3 thpffcj thpffcj   176 3月  24 2016 cloudera
drwxr-xr-x.  2 thpffcj thpffcj   127 3月  24 2016 conf
-rw-r--r--.  1 thpffcj thpffcj  6172 3月  24 2016 DEVNOTES
drwxr-xr-x. 10 thpffcj thpffcj  4096 3月  24 2016 docs
drwxr-xr-x.  2 thpffcj thpffcj  8192 3月  24 2016 lib
-rw-r--r--.  1 thpffcj thpffcj 25903 3月  24 2016 LICENSE
-rw-r--r--.  1 thpffcj thpffcj   249 3月  24 2016 NOTICE
-rw-r--r--.  1 thpffcj thpffcj  1779 3月  24 2016 README
-rw-r--r--.  1 thpffcj thpffcj  1585 3月  24 2016 RELEASE-NOTES
drwxr-xr-x.  2 thpffcj thpffcj    77 3月  24 2016 tools
</code></pre><ul>
<li>把flume配置到环境变量里</li>
</ul>
<pre><code>[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ vi ~/.bash_profile 


export FLUME_HOME=/home/thpffcj/app/apache-flume-1.6.0-cdh5.7.0-bin
export PATH=$FLUME_HOME/bin:$PATH


[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ source ~/.bash_profile 
</code></pre><ul>
<li>修改配置文件</li>
</ul>
<pre><code>[thpffcj@localhost conf]$ ls
flume-conf.properties.template  flume-env.sh.template
flume-env.ps1.template          log4j.properties
[thpffcj@localhost conf]$ cp flume-env.sh.template flume-env.sh
[thpffcj@localhost conf]$ vi flume-env.sh
</code></pre><ul>
<li>修改其中java目录</li>
</ul>
<pre><code>export JAVA_HOME=/home/thpffcj/app/jdk1.8.0_151
</code></pre><ul>
<li>检测是否安装成功，去bin目录下执行命令</li>
</ul>
<pre><code>[thpffcj@localhost bin]$ flume-ng version
Flume 1.6.0-cdh5.7.0
Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git
Revision: 8f5f5143ae30802fe79f9ab96f893e6c54a105d1
Compiled by jenkins on Wed Mar 23 11:38:48 PDT 2016
From source with checksum 50b533f0ffc32db9246405ac4431872e
</code></pre><h3 id="3-Flume实战"><a href="#3-Flume实战" class="headerlink" title="3. Flume实战"></a>3. Flume实战</h3><p><strong>1. 实战一</strong></p>
<ul>
<li>需求：从指定网络端口采集数据输出到控制台</li>
<li>使用Flume的关键就是写配置文件<ul>
<li>配置source</li>
<li>配置channel</li>
<li>配置sink</li>
<li>把以上三个组件串起来</li>
</ul>
</li>
</ul>
<ul>
<li>从官网上拷贝一个例子，进行修改<ul>
<li>a1：agent名称</li>
<li>r1：source的名称</li>
<li>k1：sink的名称</li>
<li>c1：channel的名称</li>
<li>A netcat-like source that listens on a given port and turns each line of text into an event.<ul>
<li>type – The component type name, needs to be netcat</li>
<li>bind – Host name or IP address to bind to</li>
<li>port – Port # to bind to</li>
</ul>
</li>
<li>Logs event at INFO level. Typically useful for testing/debugging purpose. <ul>
<li>type – The component type name, needs to be logger</li>
</ul>
</li>
<li>The events are stored in an in-memory queue with configurable max size.<ul>
<li>type – The component type name, needs to be memory</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code># example.conf: A single-node Flume configuration

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = thpffcj
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre><ul>
<li>新建一个配置文件，我这里直接放在conf目录下，将上面修改的配置文件拷贝到里面</li>
</ul>
<pre><code>[thpffcj@localhost conf]$ vi example.conf
</code></pre><ul>
<li>启动agent<ul>
<li>$ bin/flume-ng agent -n $agent_name -c conf -f conf/flume-conf.properties.template</li>
</ul>
</li>
</ul>
<ul>
<li>\是为了转义回车，这是一条命令</li>
</ul>
<pre><code>[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ bin/flume-ng agent --name a1 \
--conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/example.conf -Dflume.root.logger=INFO,console

...
2018-01-10 18:58:01,955 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:173)] Starting Sink k1
2018-01-10 18:58:01,956 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:184)] Starting Source r1
2018-01-10 18:58:01,958 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.source.NetcatSource.start(NetcatSource.java:155)] Source starting
2018-01-10 18:58:02,017 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.source.NetcatSource.start(NetcatSource.java:169)] Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/192.168.92.130:44444]
</code></pre><ul>
<li>现在已经启动了，但是没有任何输出，我们监听在44444端口，我们就在44444上输出点数据出来</li>
</ul>
<pre><code>[thpffcj@localhost ~]$ telnet thpffcj 44444
Trying 192.168.92.130...
Connected to thpffcj.
Escape character is &apos;^]&apos;.
hello
OK
</code></pre><ul>
<li>我们发现已经有日志输出了</li>
</ul>
<pre><code>2018-01-10 19:03:29,596 (SinkRunner-PollingRunner-DefaultSinkProcessor) 
[INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] 
Event: { headers:{} body: 68 65 6C 6C 6F 0D                               hello. }
</code></pre><ul>
<li>再随便写点东西</li>
</ul>
<pre><code>world
OK
welcome
OK
flume
OK
</code></pre><ul>
<li>发现flume都收集到了</li>
</ul>
<pre><code>2018-01-10 19:05:19,613 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 77 6F 72 6C 64 0D                               world. }
2018-01-10 19:05:20,602 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 77 65 6C 63 6F 6D 65 0D                         welcome. }
2018-01-10 19:05:22,857 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 66 6C 75 6D 65 0D                               flume. }
</code></pre><ul>
<li>我们看一下日志信息：<ul>
<li>Event是Flume数据传输的基本单元</li>
<li>Event = 可选的header + byte array</li>
</ul>
</li>
</ul>
<p><strong>2. 实战二</strong></p>
<ul>
<li>需求：监控一个文件实时采集新增的数据输出到控制台</li>
<li>Agent选型：exec source + memory channel + logger sink<ul>
<li>Exec source runs a given Unix command on start-up and expects that process to continuously produce data on standard out (stderr is simply discarded, unless property logStdErr is set to true). <ul>
<li>type     – The component type name, needs to be exec</li>
<li>command    – The command to execute</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>修改配置文件，data.log是个空文件</li>
</ul>
<pre><code># Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/thpffcj/data/data.log
a1.sources.r1.shell = /bin/sh -c

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre><ul>
<li>新建一个配置文件添加上述内容</li>
</ul>
<pre><code>[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ vi conf/exec-memory-logger.conf
</code></pre><ul>
<li>启动flume</li>
</ul>
<pre><code>[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ bin/flume-ng agent --name a1 --conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/exec-memory-logger.conf -Dflume.root.logger=INFO,console
</code></pre><ul>
<li>在data.log里添加内容</li>
</ul>
<pre><code>[thpffcj@localhost data]$ echo hello &gt;&gt; data.log 
[thpffcj@localhost data]$ echo world &gt;&gt; data.log
</code></pre><ul>
<li>发现也做到了实时监控某一个文件并把最新的内容输出到控制台</li>
</ul>
<pre><code>2018-01-10 19:21:50,230 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 68 65 6C 6C 6F                                  hello }
2018-01-10 19:21:59,233 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 77 6F 72 6C 64                                  world }
</code></pre><p><strong>3. 实战三</strong></p>
<ul>
<li>需求：将A服务器上的日志实时采集到B服务器</li>
<li>Agent选型：<ul>
<li>exec source + memory channel + avro sink</li>
<li>avro source + memory channel + logger sink</li>
<li>This sink forms one half of Flume’s tiered collection support. <ul>
<li>type – The component type name, needs to be avro</li>
<li>hostname – The hostname or IP address to bind to</li>
<li>port – The port # to listen on</li>
</ul>
</li>
<li>Listens on Avro port and receives events from external Avro client streams.<ul>
<li>type –     The component type name, needs to be avro</li>
<li>bind –     hostname or IP address to listen on</li>
<li>port – Port # to bind to</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>所以我们要写两个配置文件</p>
</li>
<li><p>exec-memory-avro.conf</p>
</li>
</ul>
<pre><code># Name the components on this agent
exec-memory-avro.sources = exec-source
exec-memory-avro.sinks = avro-sink
exec-memory-avro.channels = memory-channel

# Describe/configure the source
exec-memory-avro.sources.exec-source.type = exec
exec-memory-avro.sources.exec-source.command = tail -F /home/thpffcj/data/data.log
exec-memory-avro.sources.exec-source.shell = /bin/sh -c

# Describe the sink
exec-memory-avro.sinks.avro-sink.type = avro
exec-memory-avro.sinks.avro-sink.hostname = thpffcj
exec-memory-avro.sinks.avro-sink.port = 44444

# Use a channel which buffers events in memory
exec-memory-avro.channels.memory-channel.type = memory

# Bind the source and sink to the channel
exec-memory-avro.sources.exec-source.channels = memory-channel
exec-memory-avro.sinks.avro-sink.channel = memory-channel
</code></pre><ul>
<li>avro-memory-logger.conf</li>
</ul>
<pre><code># name the components on this agent
avro-memory-logger.sources = avro-source
avro-memory-logger.sinks = logger-sink
avro-memory-logger.channels = memory-channel

# Describe/configure the source
avro-memory-logger.sources.avro-source.type = avro
avro-memory-logger.sources.avro-source.bind = thpffcj
avro-memory-logger.sources.avro-source.port = 44444

# Describe the sink
avro-memory-logger.sinks.logger-sink.type = logger

# Use a channel which buffers events in memory
avro-memory-logger.channels.memory-channel.type = memory

# Bind the source and sink to the channel
avro-memory-logger.sources.avro-source.channels = memory-channel
avro-memory-logger.sinks.logger-sink.channel = memory-channel
</code></pre><ul>
<li>将两个配置文件写入</li>
</ul>
<pre><code>[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ vi conf/exec-memory-avro.conf
[thpffcj@localhost apache-flume-1.6.0-cdh5.7.0-bin]$ vi conf/avro-memory-logger.conf
</code></pre><ul>
<li>先启动avro-memory-logger</li>
</ul>
<pre><code>[thpffcj@localhost ~]$ flume-ng agent \
&gt; --name avro-memory-logger \
&gt; --conf $FLUME_HOME/conf \
&gt; --conf-file $FLUME_HOME/conf/avro-memory-logger.conf \
&gt; -Dflume.root.logger=INFO,console

...
2018-01-10 20:09:56,836 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.register(MonitoredCounterGroup.java:120)] Monitored counter group for type: SOURCE, name: avro-source: Successfully registered new MBean.
2018-01-10 20:09:56,836 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:96)] Component type: SOURCE, name: avro-source started
2018-01-10 20:09:56,843 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.source.AvroSource.start(AvroSource.java:253)] Avro source avro-source started.
</code></pre><ul>
<li>先启动exec-memory-avro</li>
</ul>
<pre><code>[thpffcj@localhost ~]$ flume-ng agent \
&gt; --name exec-memory-avro \
&gt; --conf $FLUME_HOME/conf \
&gt; --conf-file $FLUME_HOME/conf/exec-memory-avro.conf \
&gt; -Dflume.root.logger=INFO,console

...
2018-01-10 20:12:05,192 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:96)] Component type: SOURCE, name: exec-source started
2018-01-10 20:12:05,219 (lifecycleSupervisor-1-1) [WARN - org.apache.flume.api.NettyAvroRpcClient.configure(NettyAvroRpcClient.java:634)] Using default maxIOWorkers
2018-01-10 20:12:05,670 (lifecycleSupervisor-1-1) [INFO - org.apache.flume.sink.AbstractRpcSink.start(AbstractRpcSink.java:303)] Rpc sink avro-sink started.
</code></pre><ul>
<li>现在我们开始测试</li>
</ul>
<pre><code>[thpffcj@localhost data]$ echo hello hadoop &gt;&gt; data.log 
[thpffcj@localhost data]$ echo hello spark &gt;&gt; data.log 
</code></pre><ul>
<li>我们发现在先启动的那个agent上收集到了日志</li>
</ul>
<pre><code>2018-01-10 20:13:37,616 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 68 65 6C 6C 6F 20 68 61 64 6F 6F 70             hello hadoop }
2018-01-10 20:13:37,617 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:94)] Event: { headers:{} body: 68 65 6C 6C 6F 20 73 70 61 72 6B                hello spark }
</code></pre><ul>
<li>日志收集过程：<ul>
<li>机器上A上监控一个文件，当我们访问主站时会有用户行为日志记录到access.log中</li>
<li>avro sink把新产生的日志输出到对应avro source指定的hostname和port上</li>
<li>通过acro source对应的agent将我们的日志输出到控制台(Kafka)</li>
</ul>
</li>
</ul>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="pagination" role="pagination">
    
    <a class="pull-left" href="/2018/01/12/Big-Data-Real-time-Streaming-Data-Processing-3/" style="float: left;">
        ← 分布式发布订阅消息系统Kafka
    </a>
    
    
    <a class="pull-right" href="/2018/01/10/Big-Data-Real-time-Streaming-Data-Processing-1/">
        初识实时流处理 →
    </a>
    
</nav>

        <div class="duoshuo">


</div>
    </div>
</section>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
				<span id="busuanzi_container_site_pv">
					本站总访问量<span id="busuanzi_value_site_pv"></span>次
				</span>	
                <p>
                    &copy; 2014<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By Thpffcj.
                </p>
                <p>私は再び1日満たすためにあなたとの重要な人々を望みます</p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://twitter.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="http://weibo.com/" title="Sina-Weibo" target="_blank"><i class="icon-sina-weibo"></i></a>&nbsp;</li>
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- ============================ END Footer =========================== -->

      <!-- Load our scripts -->
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };

    resizeHero();

    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/jquery.flexslider-min.js"></script><!-- Flexslider plugin -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$('#intro').find('img').each(function(){
  var alt = this.alt;

  if (alt){
    $(this).after('<span class="caption" style="display:none">' + alt + '</span>');
  }

  $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="gallery" />');
});
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<!-- Initiate flexslider plugin -->
<script type="text/javascript">
    $(document).ready(function($) {
      (function(){
        console.log('font');
        var getCss = function(path) {
          var head = document.getElementsByTagName('head')[0];
          link = document.createElement('link');
          link.href = path;
          link.rel = 'stylesheet';
          link.type = 'text/css';
          head.appendChild(link);
        };
        getCss('https://fonts.googleapis.com/css?family=Montserrat:400,700');
        getCss('https://fonts.googleapis.com/css?family=Open+Sans:400,600');
      })();
      $('.flexslider').flexslider({
        animation: "fade",
        prevText: "",
        nextText: "",
        directionNav: true
      });
    });
</script>

</body>
</html>
