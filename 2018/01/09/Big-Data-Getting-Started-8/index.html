<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<!--
***************  *      *     *
      8          *    *       *
      8          *  *         *
      8          **           *
      8          *  *         *
      8          *    *       *
      8          *      *     *
      8          *        *   ***********    -----Theme By Kieran(http://go.kieran.top)
-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<!--<![endif]-->

<head>
  <title>大数据相关技术拓展 | Thpffcj的树洞</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Hexo">
    <meta name="author" content="John Doe">
    <meta name="description" content="" />
    <meta name="keywords" content="" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/favicon.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
    
    <link rel="stylesheet" href="/highlightjs/vs.css" type="text/css">
    

    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->

  
  
  

  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style>
</head>

<!--
<body class="post-template">
-->
<body id="index" class="lightnav animsition">

      <!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            <li>
                <a class="sb-toggle-submenu">Works<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                        <li><a href="/" target="_BLANK" class="animsition-link">AAA</a></li>
                    
                        <li><a href="/atom.xml" target="_BLANK" class="animsition-link">BBB</a></li>
                    
                </ul>
            </li>
            
            
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a href="http://go.kieran.top/" class="animsition-link">Kieran</a></li>
                    
                    <li><a href="http://domain.com/" class="animsition-link">Name</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            <li><a href="/about.html" class="animsition-link" title="about">About</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="/img/logo.png" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Thpffcj</a></li>
                            <li class="nolink"><span>Always </span>Creative.</li>
                            
                            <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            <li><a href="https://twitter.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a></li>
                            
                            
                            <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a></li>
                            
                            
                            <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a></li>
                            
                            
                            <li><a href="http://weibo.com/" title="Sina-Weibo" target="_blank"><i class="icon-sina-weibo"></i></a></li>
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->


      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2018-01-09T01:05:13.000Z" itemprop="datePublished">
          2018-01-09
      </time>
    
</span>
                <h1>大数据相关技术拓展</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<ul>
<li>下面是这段时间系统了解Hadoop的一些记录<ul>
<li><a href="http://www.thpffcj.com/2017/12/12/Big-Data-Getting-Started-2/" target="_blank" rel="external">大数据概述</a></li>
<li><a href="http://www.thpffcj.com/2018/01/04/Big-Data-Getting-Started-3/" target="_blank" rel="external">分布式文件系统HDFS</a></li>
<li><a href="http://www.thpffcj.com/2018/01/05/Big-Data-Getting-Started-4/" target="_blank" rel="external">分布式资源调度YARN</a></li>
<li><a href="http://www.thpffcj.com/2018/01/06/Big-Data-Getting-Started-5/" target="_blank" rel="external">分布式计算框架MapReduce</a></li>
<li><a href="http://www.thpffcj.com/2018/01/07/Big-Data-Getting-Started-6/" target="_blank" rel="external">Hadoop项目实战</a></li>
<li><a href="http://www.thpffcj.com/2018/01/06/Big-Data-Getting-Started-7/" target="_blank" rel="external">Hadoop集成Spring的使用</a></li>
<li><a href="http://www.thpffcj.com/2018/01/09/Big-Data-Getting-Started-8/" target="_blank" rel="external">大数据相关技术拓展</a></li>
</ul>
</li>
</ul>
<p>这是学习Hadoop第一阶段的最后一篇记录，在系统了解Hadoop之后我们了解一下大数据相关技术的扩展，在最后了解一下Hadoop 3.X的新特性。我们现在都在学习离线处理数据，过段时间我会了解一下如何利用Spark Streaming整合一些其他框架处理实时流计算。</p>
<hr>
<h2 id="1-分布式计算框架Spark"><a href="#1-分布式计算框架Spark" class="headerlink" title="1. 分布式计算框架Spark"></a>1. 分布式计算框架Spark</h2><h3 id="1-学完MapReduce，有什么想法？"><a href="#1-学完MapReduce，有什么想法？" class="headerlink" title="1. 学完MapReduce，有什么想法？"></a>1. 学完MapReduce，有什么想法？</h3><ul>
<li>开发起来爽不爽？</li>
<li>运行速度如何？</li>
<li>框架多样性？</li>
</ul>
<h3 id="2-Spark特点"><a href="#2-Spark特点" class="headerlink" title="2. Spark特点"></a>2. Spark特点</h3><ul>
<li>我们还是采用原来的套路，先去官网看一看 <a href="http://spark.apache.org/" target="_blank" rel="external">Spark Lightning-fast cluster computing</a></li>
<li>Apache Spark is a fast and general engine for large-scale data processing.</li>
<li>Speed<ul>
<li>Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk.</li>
<li>Apache Spark has an advanced DAG execution engine that supports acyclic data flow and in-memory computing.</li>
</ul>
</li>
<li>Ease of Use<ul>
<li>Write applications quickly in Java, Scala, Python, R.</li>
<li>Spark offers over 80 high-level operators that make it easy to build parallel apps. And you can use it interactively from the Scala, Python and R shells.</li>
</ul>
</li>
<li>Generality<ul>
<li>Combine SQL, streaming, and complex analytics.</li>
<li>Spark powers a stack of libraries including SQL and DataFrames, MLlib for machine learning, GraphX, and Spark Streaming. You can combine these libraries seamlessly in the same application.</li>
</ul>
</li>
<li>Runs Everywhere<ul>
<li>Spark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3.</li>
</ul>
</li>
</ul>
<h3 id="3-Spark对比Hadoop"><a href="#3-Spark对比Hadoop" class="headerlink" title="3. Spark对比Hadoop"></a>3. Spark对比Hadoop</h3><ul>
<li>Hadoop生态系统</li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/Hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F.png" alt=""></p>
<ul>
<li>Spark生态系统：BDAS</li>
</ul>
<p><img src="http://oseihavwm.bkt.clouddn.com/Spark%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F.png" alt=""></p>
<h3 id="4-Spark开发语言及运行模式"><a href="#4-Spark开发语言及运行模式" class="headerlink" title="4. Spark开发语言及运行模式"></a>4. Spark开发语言及运行模式</h3><ul>
<li>Spark开发语言<ul>
<li>Python</li>
<li>Scala</li>
<li>Java</li>
<li>R</li>
</ul>
</li>
<li>Spark运行模式<ul>
<li>Standalone</li>
<li>Yarn</li>
<li>Mesos</li>
<li>Local</li>
</ul>
</li>
</ul>
<h3 id="5-Scala-amp-Maven安装"><a href="#5-Scala-amp-Maven安装" class="headerlink" title="5. Scala &amp; Maven安装"></a>5. Scala &amp; Maven安装</h3><ul>
<li>解压Scala</li>
</ul>
<pre><code>[root@localhost software]# ls
hadoop-2.6.0-cdh5.7.0.tar.gz  scala-2.12.4.tgz
[root@localhost software]# tar -zxvf scala-2.12.4.tgz -C /home/thpffcj/app/
</code></pre><ul>
<li>配置系统环境变量</li>
</ul>
<pre><code>[root@localhost scala-2.12.4]# vi ~/.bash_profile

export SCALA_HOME=/home/thpffcj/app/scala-2.12.4
export PATH=$SCALA_HOME/bin:$PATH

[root@localhost scala-2.12.4]# source ~/.bash_profile 
</code></pre><ul>
<li>启动Scala</li>
</ul>
<pre><code>[root@localhost scala-2.12.4]# scala
Welcome to Scala 2.12.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_151).
Type in expressions for evaluation. Or try :help.

scala&gt; 
</code></pre><ul>
<li>安装maven</li>
</ul>
<pre><code>[root@localhost software]# ls
apache-maven-3.5.2-bin.tar.gz  scala-2.12.4.tgz
hadoop-2.6.0-cdh5.7.0.tar.gz
[root@localhost software]# tar -zxvf apache-maven-3.5.2-bin.tar.gz -C /home/thpffcj/app/
</code></pre><ul>
<li>也配置到系统的环境变量中去</li>
</ul>
<pre><code>export MAVEN_HOME=/home/thpffcj/app/apache-maven-3.5.2
export PATH=$MAVEN_HOME/bin:$PATH
</code></pre><h3 id="6-Spark环境搭建及wordcount案例实现"><a href="#6-Spark环境搭建及wordcount案例实现" class="headerlink" title="6. Spark环境搭建及wordcount案例实现"></a>6. Spark环境搭建及wordcount案例实现</h3><ul>
<li>官网下载spark代码自己编译 <a href="http://spark.apache.org/docs/2.1.0/building-spark.html" target="_blank" rel="external">Building Spark</a></li>
<li>我是选择官网提供编译好的</li>
</ul>
<pre><code>[root@localhost software]# tar -zxvf spark-2.1.0-bin-hadoop2.6.tgz -C /home/thpffcj/app/
</code></pre><ul>
<li>我们到bin目录下启动spark-shell本地模式两个线程</li>
</ul>
<pre><code>[root@localhost bin]# ./spark-shell --master local[2]
</code></pre><ul>
<li>随便找一个文件</li>
</ul>
<pre><code>[root@localhost data]# cat hello.txt 
hadoop welcome
hadoop hdfs mapreduce
hadoop hdfs
[root@localhost data]# pwd
/home/thpffcj/data
</code></pre><ul>
<li>读取文件并输入</li>
</ul>
<pre><code>scala&gt; val file = sc.textFile(&quot;file:///home/thpffcj/data/hello.txt&quot;)
file: org.apache.spark.rdd.RDD[String] = file:///home/thpffcj/data/hello.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24

scala&gt; file.collect
res0: Array[String] = Array(hadoop welcome, hadoop hdfs mapreduce, hadoop hdfs)
</code></pre><ul>
<li>现在我们来实现wordcount</li>
</ul>
<pre><code>scala&gt; var a = file.flatMap(line =&gt; line.split(&quot; &quot;))
a: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at flatMap at &lt;console&gt;:26

scala&gt; a.collect
res1: Array[String] = Array(hadoop, welcome, hadoop, hdfs, mapreduce, hadoop, hdfs)

scala&gt; var b = a.map(word =&gt; (word, 1))
b: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[3] at map at &lt;console&gt;:28

scala&gt; b.collect
res3: Array[(String, Int)] = Array((hadoop,1), (welcome,1), (hadoop,1), (hdfs,1), (mapreduce,1), (hadoop,1), (hdfs,1))

scala&gt; var c = b.reduceByKey(_ + _)
c: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:30

scala&gt; c.collect
res4: Array[(String, Int)] = Array((mapreduce,1), (welcome,1), (hadoop,3), (hdfs,2)).reduceByKey(_ + _)
</code></pre><ul>
<li>使用方法链</li>
</ul>
<pre><code>scala&gt; sc.textFile(&quot;file:///home/thpffcj/data/hello.txt&quot;).flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_ + _).collect
res6: Array[(String, Int)] = Array((mapreduce,1), (welcome,1), (hadoop,3), (hdfs,2))
</code></pre><h2 id="2-分布式计算框架Flink"><a href="#2-分布式计算框架Flink" class="headerlink" title="2. 分布式计算框架Flink"></a>2. 分布式计算框架Flink</h2><h3 id="1-Flink概述"><a href="#1-Flink概述" class="headerlink" title="1. Flink概述"></a>1. Flink概述</h3><ul>
<li>一样的套路，官网：<a href="http://flink.apache.org/" target="_blank" rel="external">Flink</a></li>
<li>Apache Flink is an open-source stream processing framework for distributed, high-performing, always-available, and accurate data streaming applications.</li>
<li>Continuous Processing for Unbounded Datasets<ul>
<li><strong>First, 2 types of datasets</strong><ul>
<li>Unbounded: Infinite datasets that are appended to continuously</li>
<li>Bounded: Finite, unchanging datasets</li>
</ul>
</li>
<li><strong>Second, 2 types of execution models</strong><ul>
<li>Streaming: Processing that executes continuously as long as data is being produced</li>
<li>Batch: Processing that is executed and runs to completeness in a finite amount of time, releasing computing resources when finished</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-Flink架构"><a href="#2-Flink架构" class="headerlink" title="2. Flink架构"></a>2. Flink架构</h3><p><img src="http://oseihavwm.bkt.clouddn.com/Flink%E6%9E%B6%E6%9E%84.png" alt=""></p>
<h3 id="3-Flink实战"><a href="#3-Flink实战" class="headerlink" title="3. Flink实战"></a>3. Flink实战</h3><ul>
<li>下载解压</li>
</ul>
<pre><code>[root@localhost software]# tar -zxvf flink-1.4.0-bin-hadoop26-scala_2.11.tgz -C /home/thpffcj/app/

[root@localhost flink-1.4.0]# ls
bin   examples  LICENSE  NOTICE  README.txt  tools
conf  lib       log      opt     resources
</code></pre><ul>
<li>Start a Local Flink Cluster<ul>
<li>$ ./bin/start-local.sh  # Start Flink</li>
</ul>
</li>
</ul>
<pre><code>[root@localhost bin]# ./start-local.sh 

[root@localhost bin]# jps
9105 Jps
9079 TaskManager
8697 JobManager
</code></pre><ul>
<li>访问 <a href="http://192.168.92.130:8081" target="_blank" rel="external">http://192.168.92.130:8081</a> 我们可以看见他的UI界面</li>
<li>文档侧面有一个 Deployment &amp; Operations 我们点击他下面的CLI，里面就有怎么使用的例子</li>
</ul>
<pre><code>[root@localhost flink-1.4.0]# ./bin/flink run ./examples/batch/WordCount.jar --input file:///home/thpffcj/data/hello.txt --output file:///home/thpffcj/tmp/flink_wc_out
</code></pre><ul>
<li>查看结果</li>
</ul>
<pre><code>[root@localhost flink-1.4.0]# cat /home/thpffcj/tmp/flink_wc_out 
hadoop 3
hdfs 2
mapreduce 1
welcome 1
</code></pre><ul>
<li>关于是怎么实现的，我们可以直接到github上查看源码</li>
</ul>
<pre><code>package org.apache.flink.examples.scala.wordcount

import org.apache.flink.api.java.utils.ParameterTool
import org.apache.flink.api.scala._
import org.apache.flink.examples.java.wordcount.util.WordCountData

/**
 * Implements the &quot;WordCount&quot; program that computes a simple word occurrence histogram
 * over text files. 
 *
 * The input is a plain text file with lines separated by newline characters.
 *
 * Usage:
 * {{{
     *   WordCount --input <path></path> --output <path></path>
     * }}}
 *
 * If no parameters are provided, the program is run with default data from
 * [[org.apache.flink.examples.java.wordcount.util.WordCountData]]
 *
 * This example shows how to:
 *
 *   - write a simple Flink program.
 *   - use Tuple data types.
 *   - write and use user-defined functions.
 *
 */
object WordCount {

  def main(args: Array[String]) {

    val params: ParameterTool = ParameterTool.fromArgs(args)

    // set up execution environment
    val env = ExecutionEnvironment.getExecutionEnvironment

    // make parameters available in the web interface
    env.getConfig.setGlobalJobParameters(params)
    val text =
      if (params.has(&quot;input&quot;)) {
        env.readTextFile(params.get(&quot;input&quot;))
      } else {
        println(&quot;Executing WordCount example with default input data set.&quot;)
        println(&quot;Use --input to specify file input.&quot;)
        env.fromCollection(WordCountData.WORDS)
      }

    val counts = text.flatMap { _.toLowerCase.split(&quot;\\W+&quot;) filter { _.nonEmpty } }
      .map { (_, 1) }
      .groupBy(0)
      .sum(1)

    if (params.has(&quot;output&quot;)) {
      counts.writeAsCsv(params.get(&quot;output&quot;), &quot;\n&quot;, &quot; &quot;)
      env.execute(&quot;Scala WordCount Example&quot;)
    } else {
      println(&quot;Printing result to stdout. Use --output to specify output path.&quot;)
      counts.print()
    }
  }
}
</code></pre><p><br></p>
<hr>
<h2 id="3-大数据处理神器Beam"><a href="#3-大数据处理神器Beam" class="headerlink" title="3. 大数据处理神器Beam"></a>3. 大数据处理神器Beam</h2><h3 id="1-Google新老三驾马车"><a href="#1-Google新老三驾马车" class="headerlink" title="1. Google新老三驾马车"></a>1. Google新老三驾马车</h3><ul>
<li>老三架：GFS，MapReduce，BigTable</li>
<li>新三架：Dremel，Pregel，Caffeine</li>
</ul>
<h3 id="2-Beam概述"><a href="#2-Beam概述" class="headerlink" title="2. Beam概述"></a>2. Beam概述</h3><ul>
<li><strong><a href="https://beam.apache.org/" target="_blank" rel="external">Apache Beam: An advanced unified programming model</a></strong></li>
<li>Implement batch and streaming data processing jobs that run on any execution engine.</li>
</ul>
<h3 id="3-将WordCount的Beam程序以多种不同Runner运行"><a href="#3-将WordCount的Beam程序以多种不同Runner运行" class="headerlink" title="3. 将WordCount的Beam程序以多种不同Runner运行"></a>3. 将WordCount的Beam程序以多种不同Runner运行</h3><ul>
<li>直接按照官网执行mvn命令</li>
</ul>
<pre><code>[root@localhost software]# mvn archetype:generate \
&gt;       -DarchetypeGroupId=org.apache.beam \
&gt;       -DarchetypeArtifactId=beam-sdks-java-maven-archetypes-examples \
&gt;       -DarchetypeVersion=2.2.0 \
&gt;       -DgroupId=org.example \
&gt;       -DartifactId=word-count-beam \
&gt;       -Dversion=&quot;0.1&quot; \
&gt;       -Dpackage=org.apache.beam.examples \
&gt;       -DinteractiveMode=false
</code></pre><ul>
<li>Beam运行</li>
<li>direct方式运行<ul>
<li>$ mvn compile exec:java -Dexec.mainClass=org.apache.beam.examples.WordCount \<br> -Dexec.args=”–inputFile=pom.xml –output=counts” -Pdirect-runner</li>
</ul>
</li>
<li>spark方式运行<ul>
<li>$ mvn compile exec:java -Dexec.mainClass=org.apache.beam.examples.WordCount \<br> -Dexec.args=”–runner=SparkRunner –inputFile=pom.xml –output=counts” -Pspark-runner</li>
</ul>
</li>
</ul>
<pre><code>[root@localhost word-count-beam]# mvn compile exec:java -Dexec.mainClass=org.apache.beam.examples.WordCount \
&gt;      -Dexec.args=&quot;--inputFile=/home/thpffcj/data/hello.txt --output=counts&quot; -Pdirect-runner
</code></pre><ul>
<li>构建结束，查看结果</li>
</ul>
<pre><code>[root@localhost word-count-beam]# ll
总用量 28
-rw-r--r--. 1 root root     0 1月   9 19:56 counts-00000-of-00004
-rw-r--r--. 1 root root    11 1月   9 19:56 counts-00001-of-00004
-rw-r--r--. 1 root root    13 1月   9 19:56 counts-00002-of-00004
-rw-r--r--. 1 root root    18 1月   9 19:56 counts-00003-of-00004
-rw-r--r--. 1 root root 13429 1月   9 19:45 pom.xml
drwxr-xr-x. 4 root root    30 1月   9 19:45 src
drwxr-xr-x. 5 root root    66 1月   9 19:55 target

[root@localhost word-count-beam]# more counts*
::::::::::::::
counts-00000-of-00004
::::::::::::::
::::::::::::::
counts-00001-of-00004
::::::::::::::
welcome: 1
::::::::::::::
counts-00002-of-00004
::::::::::::::
mapreduce: 1
::::::::::::::
counts-00003-of-00004
::::::::::::::
hadoop: 3
hdfs: 2
</code></pre><p><br></p>
<hr>
<h2 id="4-Hadoop3-x新特性"><a href="#4-Hadoop3-x新特性" class="headerlink" title="4. Hadoop3.x新特性"></a>4. Hadoop3.x新特性</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><ul>
<li><strong><a href="http://hadoop.apache.org/docs/r3.0.0/" target="_blank" rel="external">Apache Hadoop 3.0.0</a></strong></li>
<li>Apache Hadoop 3.0.0 incorporates a number of significant enhancements over the previous major release line (hadoop-2.x).</li>
<li>This release is generally available (GA), meaning that it represents a point of API stability and quality that we consider production-ready.</li>
<li>Minimum required Java version increased from Java 7 to Java 8</li>
</ul>
<h3 id="2-Common主要改进"><a href="#2-Common主要改进" class="headerlink" title="2. Common主要改进"></a>2. Common主要改进</h3><ul>
<li>Shell script rewrite</li>
</ul>
<h3 id="3-HDFS主要改进"><a href="#3-HDFS主要改进" class="headerlink" title="3. HDFS主要改进"></a>3. HDFS主要改进</h3><ul>
<li>Support for erasure coding in HDFS</li>
<li>Support for more than 2 NameNodes</li>
<li>Intra-datanode balancer</li>
<li>Default ports of multiple services have been changed</li>
</ul>
<h3 id="4-YARN主要改进"><a href="#4-YARN主要改进" class="headerlink" title="4. YARN主要改进"></a>4. YARN主要改进</h3><ul>
<li>YARN Timeline Service v.2</li>
<li>Support for Opportunistic Containers and Distributed Scheduling</li>
</ul>
<h3 id="5-MapReduce主要改进"><a href="#5-MapReduce主要改进" class="headerlink" title="5. MapReduce主要改进"></a>5. MapReduce主要改进</h3><ul>
<li>MapReduce task-level native optimization</li>
<li>Reworked daemon and task heap management</li>
</ul>
<h3 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h3><ul>
<li>Shaded client jars</li>
<li>Support for Microsoft Azure Data Lake and Aliyun Object Storage System filesystem connectors</li>
</ul>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="pagination" role="pagination">
    
    <a class="pull-left" href="/2018/01/09/Scala-Syntax/" style="float: left;">
        ← Scala 基础
    </a>
    
    
    <a class="pull-right" href="/2018/01/08/Big-Data-Getting-Started-7/">
        Hadoop集成Spring的使用 →
    </a>
    
</nav>

        <div class="duoshuo">


</div>
    </div>
</section>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
				<span id="busuanzi_container_site_pv">
					本站总访问量<span id="busuanzi_value_site_pv"></span>次
				</span>	
                <p>
                    &copy; 2014<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By Thpffcj.
                </p>
                <p>私は再び1日満たすためにあなたとの重要な人々を望みます</p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://twitter.com/" title="Twitter" target="_blank"><i class="icon-twitter"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://www.facebook.com/" title="Facebook" target="_blank"><i class="icon-facebook"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="https://google.com/" title="Google-Plus" target="_blank"><i class="icon-google-plus"></i></a>&nbsp;</li>
                    
                    
                    <li><a href="http://weibo.com/" title="Sina-Weibo" target="_blank"><i class="icon-sina-weibo"></i></a>&nbsp;</li>
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- ============================ END Footer =========================== -->

      <!-- Load our scripts -->
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };

    resizeHero();

    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/jquery.flexslider-min.js"></script><!-- Flexslider plugin -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$('#intro').find('img').each(function(){
  var alt = this.alt;

  if (alt){
    $(this).after('<span class="caption" style="display:none">' + alt + '</span>');
  }

  $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="gallery" />');
});
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<!-- Initiate flexslider plugin -->
<script type="text/javascript">
    $(document).ready(function($) {
      (function(){
        console.log('font');
        var getCss = function(path) {
          var head = document.getElementsByTagName('head')[0];
          link = document.createElement('link');
          link.href = path;
          link.rel = 'stylesheet';
          link.type = 'text/css';
          head.appendChild(link);
        };
        getCss('https://fonts.googleapis.com/css?family=Montserrat:400,700');
        getCss('https://fonts.googleapis.com/css?family=Open+Sans:400,600');
      })();
      $('.flexslider').flexslider({
        animation: "fade",
        prevText: "",
        nextText: "",
        directionNav: true
      });
    });
</script>

</body>
</html>
